{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA (Principal Component Analysis) é um algoritmo de redução de dimensionalidade que tem como objetivo principal acelerar o treinamento de modelos, simplificando os dados sem perder informações significativas. A ideia é reduzir a dimensionalidade do dataset, preservando a variância dos dados.  \n",
    "\n",
    "Além de melhorar a eficiência computacional, o PCA também é uma ferramenta poderosa para visualização de dados. Ao reduzir o número de dimensões para 2 ou 3, é possível representar de forma condensada conjuntos de dados de alta dimensionalidade, permitindo uma visão mais clara e intuitiva das relações entre os dados. Muitas vezes, essa visualização ajuda a identificar padrões, como os clusters.  \n",
    "\n",
    "Esse algoritmo é particularmente útil quando se trabalha com grandes volumes de dados e muitas variáveis e quando as variáveis têm grande correlação entre si, pois ajuda a reduzir o tempo de execução dos modelos, mantendo a maior parte da variabilidade dos dados.  \n",
    "\n",
    "No entanto, é crucial lembrar que a redução de dimensionalidade deve ser usada com cautela. Antes de aplicá-la, recomenda-se sempre que possível treinar os modelos utilizando os dados originais, pois, ao reduzir a dimensionalidade, costuma haver perda de informações (não necessariamente, mas em geral, sim). Esse comprometimento *pode* impactar negativamente o desempenho de alguns modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
